---
title: 임상연구 설계와 분석을 위한 통계 방법
# subtitle: Penalized Regression Approach for Multivariate Analysis of Spectroscopy Data
author: \textbf{Boncho Ku}, Ph.D., Senior researcher
institute: KM Fundamental Research Division, Korea Institute of Oriental Medicine
date: $16^{\mathrm{th}}$ November, 2017
output: 
  beamer_presentation: 
    fonttheme: serif
    includes:
      in_header: presentation-header-new.tex
      incremental: no
    keep_tex: yes
    slide_level: 2
    theme: metropolis
    toc: no
urlcolor: blue
classoption: xcolor=dvipsnames
fontsize: 9pt
geometry: paperwidth=297mm, paperheight=210mm, textwidth=247mm, textheight=154.6mm
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r knitr_init, echo=FALSE, results="hide", message=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = '..')
options(max.print = 10000)
knitr::opts_chunk$set(eval = TRUE,
                      echo = FALSE,
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      tidy=TRUE,
                      message=FALSE,
                      warning=FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      fig.path="Figures/",  # Set the figure options
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      fig.keep='all', fig.retina=2)
```

```{r Initialization, echo = F, results = "hide", message = F, cache = F}
rm(list = ls())
library(MASS)
library(reshape2)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(lubridate)
library(ChemoSpec)
library(prospectr)
library(inspectr)
library(pls)
library(rmarkdown)
library(knitr)
library(moonBook)
library(ztable)
library(htmlTable)
library(ggthemes)
library(grid)
library(gridExtra)
library(latex2exp)
library(nlme)
library(lsmeans)
library(car)
library(multcomp)
library(xtable)
library(kableExtra)
library(viridis)
library(GGally)
library(RColorBrewer)
library(Hmisc)

options(knitr.table.format = "latex")
```

# Chapter I: \LARGE{Overview of Statistics}

## Famous quotes about statistics

\begin{mdframed}[backgroundcolor = gray!30]

\textit{There are three types of lies: lies, damn lies, and \textbf{STATISTICS}} (Benjamin Disraeli)

\textit{Fact are stubborn things, but \textbf{STATISTICS} are pliable} (Mark Twain)

and so on ...

\end{mdframed}



Huge number of quotes about statistics commented it in sarcastic tone

$\rightarrow$ mostly hard to refute

## Really?
\LARGE
\textbf{However ...}

\vspace{0.5cm}

Statistics itself always provides useful information and allows us to maintain objective perspective based on DATA

## What is Statistics?

\large{So then, what is statistics??}

\vspace{0.5cm}
\begin{columns}
  \begin{column}{0.4\textwidth}
    \begin{center}
      \includegraphics[width = 2.5cm, height = 2.5cm]{StatisticsWords_Meg.jpg}
    \end{center}
  \end{column}
  \begin{column}{0.6\textwidth}
    \begin{center}
      \includegraphics[width = 4.8cm, height = 2.5cm]{wordcloud-biostatics.png}
    \end{center}
  \end{column}
\end{columns}

\tiny{$^{\dagger}$ Each wordcloud was cited from \href{http://blog.trident.edu/-temporary-slug-8756cc7e-1d1b-458e-94e2-3ff603f80c9e}{Trident University International} and \href{http://www.augusta.edu/mcg/dphs/biostats/research/index.php}{Augusta University}, respectively.}

\vspace{0.3cm}
\normalsize

\begin{tcolorbox}[colback=gray!10,colframe=black, title=\textbf{Statistics}]
Concerning with \textbf{collection}, \textbf{organization}, \textbf{summarization} and \textbf{analysis} of \textbf{DATA}
\end{tcolorbox}
<!--   -->


## Main Pillars of Statistics 
\LARGE

### The most important things in statistics 
\normalsize

1. Data (sample)
    - Investigation, experiment, and survey
    - Gathering numbers (for quantitative analysis)
2. Description or Summarization
    - Table, chart, and so on
    - Based on summarized statistics (e.g. mean, standard deviation, median, ...)
3. Inference
    - Numerous statistical tests and models based on probability theory
    - e.g. two-sample t-test, ANOVA, ANCOVA, regression, and so on

## Why should we collect data (sample)? 

### Measure everything from POPULATION

- Benefits
    - You will get exactly correct answer
    - No need to meet an awkward statistician LIKE ME

- If you had a plenty of 
    - Money (typing ``SHOW ME THE MONEY'' may help your budget)
    - Time (TOO SHORT TO COLLECT data of entire population)

### Inferential approach based on SAMPLE

  - If we have a proper sample that represents the whole population, you can get NEARLY the correct answer
  - Estimation and hypothesis testing

## Parameter vs. Estimates

### Parameter

Parameters exist somewhere in the universe $\rightarrow$ the true value representing the target population

From the view of \textit{frequentist}, 

  - Parameters are fixed $\rightarrow$ never changing
  - Parameters exists but we never know the true value of them
  - But we can ``guess'' them from sample

## Parameter vs. Estimates

### Estimates

 - Estimating parameters based on the given samples (data)
 - Estimates have a variation in accordance with different samples or data
 
\begin{mdframed}[backgroundcolor = gray!30]

The data is an aspect of the real world we have captured

\end{mdframed}
 
 - How good is our estimation?
    - Estimation inevitably involves \textbf{ERROR}
    - Error measures: standard error (SE) $\rightarrow$ reliability of an estimate

$$
  \mathrm{SE} = \frac{\sigma}{\sqrt{N}}
$$

\begin{mdframed}[backgroundcolor = gray!30]
\textbf{\textit{Measurement is ubiquitous $\rightarrow$ then error is also ubiquitous.}}
\end{mdframed}


## Type of variables

\textbf{Data consist of a set of independent sample and measured variables}
<!-- \rowcolors{2}{gray!6}{white} -->
\begin{table}
  \centering
  \caption{Types of variable based on their scales}
  \begingroup\footnotesize
  \begin{tabular}{lp{12em}p{8em}}
    \toprule
  \textbf{Scale}  &  \textbf{Example}                                                & \textbf{Operation} \\
    \midrule 
  \multicolumn{3}{L{5cm}}{\textbf{Qualitative (질적변수)}} \\
  \hspace{2.5mm} Nominal (명목)  & sex, marital status, blood type, race, eye colour, religion, ... & counting          \\ 
  \hspace{2.5mm} Ordinal (순서)  & grade, education level, preference, severity, ...                & counting, ranking \\
  \multicolumn{3}{L{5cm}}{\textbf{Quantitative (양적변수)}} \\
  \hspace{2.5mm} Interval (구간) & temperature, IQ, SAT score, ...                                  & counting, ranking, $+$, $-$ \\
  \hspace{2.5mm} Ratio (비율)    & distance, length, height, weight, BMI, blood pressure, ...       & counting, ranking, $+$, $-$, $\times$, $\div$ \\
  \bottomrule
  \end{tabular}
  \endgroup
\end{table}

## Can we separate types of variable clearly? 

Continuous variable is limited by the precision of the measurement

### Example

- Height: measured to the nearest centimeter $\rightarrow$ continuous variable?
- Age: measured to the year but theoretically, measured to any level of precision (e.g. month, day, and time)

\begin{mdframed}[backgroundcolor = gray!30]
In practice, all variables are discrete but some variables can be treated as continuous when its distribution can be well approximated by a continuous distribution.
\end{mdframed}

## How to express your data?

\begin{mdframed}[backgroundcolor = gray!30]
Data themselves are just a bunch of numbers $\rightarrow$ how to extract meaningful information from data?
\end{mdframed}

### Descriptive statistics 

- Summary statistics: all information of data are represented by a certain type of numbers
    - Example: mean, median, proportion, standard deviation, interquartile range, percentile, ... $\rightarrow$ developing ``\textit{statphobia}''

```{r summary-ex1, results = "asis"}
library(xtable)
library(reporttools)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)

data(mpg)
df <- data.frame(mpg %>% select(displ, year, cyl, cty, hwy))
tableContinuous(vars = df, stats = c("n", "min", "q1", "median", "mean", "q3", "max", "s", "iqr"),
                caption.placement = "top", cap = "Descriptive statistics of ``mpg'' dataset", 
                lab = "tab:demo-1", longtable = F, table.placement = "H")
```

## How to express your data?

### Example of polar area diagram by Florence Nightingale (1820 $\sim$ 1910)

\begin{center}
  \includegraphics[width = 10cm, height = 6cm]{Nightingale-mortality.jpg}
\end{center}

## How to express your data?

### Example of data visualization

```{r mpg-example, message = F, fig.pos = "H", fig.width = 11, fig.height = 9, out.width = "8cm", out.height = "6cm", dpi = 250,  fig.align = "center", fig.cap = "Data visualization examples for ``mpg'' dataset. All plots are available at http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html", cache = T}
theme_set(theme_classic())
g <- ggplot(mpg, aes(cty))
g1 <- g + geom_density(aes(fill=factor(cyl)), alpha=0.8) + 
     labs(title="Density plot", subtitle="City Mileage Grouped by Number of cylinders",
          caption="Source: mpg", x="City Mileage", fill="# Cylinders") + 
  scale_fill_manual(values = c("white", "green", "orange", "red"))

theme_set(theme_bw())
g <- ggplot(mpg, aes(manufacturer, cty))
g2 <- g + geom_boxplot() + 
          geom_dotplot(binaxis='y', stackdir='center', dotsize = .5, fill="red") +
          theme(axis.text.x = element_text(angle=65, vjust=0.6)) + 
          labs(title="Box plot + Dot plot", subtitle="City Mileage vs Class: Each dot represents 1 row in source data",
               caption="Source: mpg", x="Class of Vehicle", y="City Mileage")
       
library(ggplot2)
theme_set(theme_bw())  # pre-set the bw theme.
g <- ggplot(mpg, aes(cty, hwy))
g3 <- g + geom_count(col="tomato3", show.legend=F) +
  labs(subtitle="mpg: city vs highway mileage", y="hwy", x="cty", title="Counts Plot")

library(ggplot2)
theme_set(theme_classic())
freqtable <- table(mpg$manufacturer)
df <- as.data.frame.table(freqtable)

g <- ggplot(df, aes(Var1, Freq))
g4 <- g + geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
  labs(title="Bar Chart", subtitle="Manufacturer of vehicles", 
       caption="Source: Frequency of Manufacturers from 'mpg' dataset") + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))

grid.arrange(g1, g2, g3, g4, ncol = 2)
```

## How to express your data?

### Data visualization

\begin{mdframed}[backgroundcolor = gray!30]
Sometimes, a graph provides us more useful information than complex tables
\end{mdframed}

### Various types of statistical graphs

- Histogram, boxplot, Q-Q plot, scatterplot, ...
- Do NOT rely only on NUMBERS, Do draw a PLOT!!


## Is description of data fully enough?

Again, data are the small aspect of the real world. 

Statistical inference provides us more reasonable interpretation regarding to the uncertainty of data.

\begin{tcolorbox}[colback=gray!10,colframe=black, title=\textbf{Two main aspects of statistical inference}]
\begin{itemize}
\tightlist
  \item \textbf{Estimation}
  \begin{itemize}
  \tightlist
    \item Point estimation
    \item \textbf{Interval estimation}
  \end{itemize}
  \item \textbf{Hypothesis testing}
\end{itemize}
\end{tcolorbox}

<!-- : difficult to figure out whether the estimate is good or bad -->
<!-- : quantifying the uncertainty in the estimate (HOW?) -->
 <!-- \begin{itemize} -->
 <!--  \tightlist -->
 <!--    \item Making a decision about the population parameter based on the knowledge of the sample estimate -->
 <!--  \end{itemize} -->

## Estimation

### Point estimation

- Simply using sample statistic (e.g., sample mean, proportion and standard deviation)
- Good estimate: unbiased (to target) and have small variance (be precise)

\begin{center}
  \includegraphics[width = 7cm, height = 2cm]{bias.png}
\end{center}

- Disadvantages
    - No way to validate whether our estimate is good or bad
    - Example: if someone shows an estimate and it was taken from only one sample, can you trust the value of estimate? 

## Estimation

### Interval estimation

- Almost all point estimates are wrong
- Quantifying the uncertainty in the estimate $\rightarrow$ \textbf{standard error}
- Plus the concept of belief or probability that the parameter can be expected to be lie within an interval $\rightarrow$ $(1-\alpha)$\% confidence interval
- $(1-\alpha)$ is called as \textbf{confidence level}, representing the magnitude of our belief

## Estimation

### $(1-\alpha)$\% confidence interval

- General form of $(1-\alpha)$\% confidence interval for population mean $\mu$

$$
  \hat{\theta} \pm \Phi^{-1}(\alpha /2)\frac{\sigma}{\sqrt{n}}
$$

- $\hat{\theta}$: a point estimator
- $\Phi^{-1}(\alpha /2)$: inverse of cumulative density function $\Phi$ at the $\alpha /2$\textsuperscript{th} percentile

### Interpretation

<!-- - A shorter interval is better under the equal confidence level $\rightarrow$ increasing $n$ -->
- 모수가 이 구간에 포함될 확률이 95\%? $\rightarrow$ WRONG!!
- 모든 가능한 모수에 대한 표본 추정치의 신뢰구간들 중 95\%가 모수 $\theta$를 포함 $\rightarrow$ OK!!
    
## Simulation result of 95\% confidence interval of $\mathbf{\mu}$

```{r sim-95CI, message = F, fig.pos = "H", fig.width = 10, fig.height = 5, out.width = "10cm", out.height = "5cm", dpi = 250, fig.align = "center", fig.cap = "95\\% confidence intervals for 100 independent drawn samples with $n = 100$.", cache = T}
smpl_mean_sample_ci <- function(n, p=0.95, pop_mean=0, pop_sd=1) {
  smpl <- rnorm(n, pop_mean, pop_sd)
  smpl_sd <- sd(smpl)
  smpl_mean <- mean(smpl)
  tailprob <- (1 - p) / 2
  q <- -qt(tailprob, df=(n - 1), lower.tail=TRUE)
  se <- smpl_sd / sqrt(n)
  ci <- data.frame(ci_lb = smpl_mean - q * se,
                   ci_ub = smpl_mean + q * se)
  ci
}

set.seed(19811202)
tmp2 <- rdply(100, smpl_mean_sample_ci(100, 95 / 100))
tmp2 <- tmp2 %>% 
  mutate(n = seq_len(100), 
         contains_mean = ((0 > ci_lb) & (0 < ci_ub)))

ggplot(tmp2, aes(x = n, ymin = ci_lb, ymax = ci_ub, colour = contains_mean)) + 
  geom_linerange(size = 1.2) + geom_hline(yintercept = 0, colour = "blue", linetype = "dashed", size = 0.5) + 
  scale_x_continuous("# of samples") + 
  scale_y_continuous(sprintf("%d%% Confidence interval", 95)) + 
  scale_colour_manual(values = c("red", "black")) + 
  annotate("text", x = 70, y = -0.5, label = sprintf("# of intervals containing true mean: %d", sum(tmp2$contains_mean)), hjust = 0) + 
  annotate("text", x = 70, y = -0.55, label = sprintf("# of intervals NOT containing true mean: %d", sum(!tmp2$contains_mean)), hjust = 0) + 
  theme(legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

\begin{mdframed}[backgroundcolor = gray!30]
동일한 방법으로 100번 $n$개의 표본을 추출했을 때 구한 신뢰구간 중 95개 정도의 신뢰구간이 $\mu$를 포함
\end{mdframed}

## Hypothesis testing

\begin{mdframed}[backgroundcolor = gray!30]
표본으로부터 얻은 정보를 토대로 모집단에 대한 특정 가설을 받아들이거나(accept) 혹은 기각(reject)을 위한 통계적 의사결정 방법
\end{mdframed}

  - 대한민국 40대 남성의 평균 수축기 혈압은 125 mmHg 이다
  - 농촌과 도시지역의 치매 유병률은 다르다
  - 소화불량 환자의 변증별 복압도는 다르다
  
\begin{tcolorbox}[colback=gray!10,colframe=black, title=\textbf{통계적 가설의 유형}]
  \begin{itemize}
    \item \textbf{귀무가설(null hypothesis)} denoted as $\bm{\mathrm{H}_{0}}$
    \item \textbf{대립가설(alternative hypothesis)} denoted as $\bm{\mathrm{H}_{1}}$
  \end{itemize}
\end{tcolorbox}

## Hypothesis testing

### 귀무가설

- 기존에 알려진 사실 또는 비교 대상과 차이 없음으로 설정
- $\mathrm{H}_{0}: \mu = a$, $\mathrm{H}_{0}: \mu_{1} = \mu_{2}$

### 대립가설

- 새로운 사실, 현재 믿음에 대한 변화 또는 연구자가 입증하고 싶어하는 가설로 설정
- $\mathrm{H}_{1}: \mu > a$, $\mathrm{H}_{1}: \mu < a$, $\mathrm{H}_{1}: \mu \neq a$, $\mathrm{H}_{1}: \mu_{1} \neq \mu_{2}$

\textbf{보수적 의사결정방법(conservative decision making rule)}

## Hypothesis testing

### Two types of error in hypothesis testing

가설 검정은 다음 두 가지 오류를 반드시 수반

- 1종 오류(type I error): $\mathrm{H}_{0}$이 참(true)임에도 불구하고 $\mathrm{H}_{0}$를 기각($\mathrm{H}_{1}$ 채택)
    - 일반적으로 $\alpha$로 표기: $P(\mathrm{reject~H_{0}} | \mathrm{true ~ H_{0}})$
    - False positive rate (FPR)
    - 1종 오류 발생확률의 허용수준: 유의수준(significance level $\alpha$)
    
- 2종 오류(type II error): $\mathrm{H}_{0}$이 거짓(false)일 때  $\mathrm{H}_{0}$를 채택($\mathrm{H}_{1}$ 기각)
    - $\beta$로 표기: $P(\mathrm{reject~H_{1}} | \mathrm{true ~ H_{1}})$
    - False negative rate (FNR)
    - 검정력: $1-\beta$
    
## Hypothesis testing

<!-- 새 기준 이전 정상 수축기 혈압의 평균은 $\mu = 123 mmHg$이고 그 표준편차는 $\sigma = 10 mmHg$인 정규분포를 따른다고 알려져 있다. 정상인  -->

\begin{table}
  \centering
  \caption{Types of errors in hypothesis testing}
  \begingroup\footnotesize
  \begin{tabular}{cccc}
  \toprule
                              &                         & \multicolumn{2}{c}{\textbf{True state}} \\ \cmidrule(l){3-4}
                              &                         & True $\mathrm{H}_{0}$    & True $\mathrm{H}_{1}$ \\
  \midrule
  \textbf{Test result}       & Accept $\mathrm{H}_{0}$  & Correct ($1-\alpha$)     & Type II error ($\beta$)\\
                             & Accept $\mathrm{H}_{1}$  & Type I error ($\alpha$)  &  Correct ($1-\beta$) \\
  \bottomrule                  
  \end{tabular}
  \endgroup
\end{table}

어떻게 하면 1종 오류와 2종 오류를 동시에 줄일 수 있을까? 

- $\alpha$ $\uparrow$ $\rightarrow$ $\beta$ $\downarrow$
- $\beta$ $\downarrow$ $\rightarrow$ $\alpha$ $\uparrow$
- 주어진 상황에서 두 오류를 동시에 줄이는 것은 불가능

## Hypothesis testing

\begin{tcolorbox}[colback=gray!10,colframe=black, title=\textbf{Example: blood pressure cutpoint}]
  \scriptsize  최근 미국의 심장협회(AHA)와 심장병학(ACC)가 고혈압의 기준을 수축기 혈압 140/80 mmHg에서 130/80 mmHg로 하향 조정한다는 내용을 현지 매체들이 보도했다. 새 기준으로 변경한 경우 정상으로 판명된 사람이 고혈압으로 진단되는 비율을 알기 위해 정상인과 과거 고혈압으로 진단 받은 환자 각각 50명 씩 표집했다. 그 결과 정상으로 판명된 사람들의 수축기 혈압 평균은 123 mmHg이고 표준편차는 7 mmHg로 조사되었으며, 고혈압으로 진단받았던 환자의 수축기 혈압 평균은 147 mmHg이고 표준편차는 10 mmHg로 조사되었다. 두 집단의 분포는 정규분포를 따른다고 알려져 있다. 
\end{tcolorbox}

```{r dist-2, message = F, fig.pos = "H", fig.width = 10, fig.height = 5, out.width = "10cm", out.height = "4cm", dpi = 250, fig.align = "center", fig.cap = "Distribution of normal and hypertention groups", cache = F}
mu1 <- 123; s1 <- 7; mu2 <- 147; s2 <- 5
normal <- function(x) dnorm(x, mean = mu1, sd = s1)
hyptens <- function(x) dnorm(x, mean = mu2, sd = s2)
xvalues <- data.frame(x = c((mu1 - 3*s1), (mu1 + 3*s1)))

hypens.c1 <- function(x) { 
  hyp <- hyptens(x)
  hyp[x > 140] <- NA
  return(hyp)
}

hypens.c2 <- function(x) { 
  hyp <- normal(x)
  hyp[x <= 130] <- NA
  return(hyp)
}

ggplot(data = xvalues) + aes(x = xvalues) + stat_function(fun = normal, size = 1.2, color = "black") + 
  stat_function(fun = hyptens, size = 1.2, color = "red") + xlim(c((mu1 - 3*s1), (mu2 + 3*s2))) + 
  stat_function(fun = hypens.c1, geom = "area", fill = "red", alpha = 0.3) + 
  stat_function(fun = hypens.c2, geom = "area", fill = "gray", alpha = 0.3) + 
  geom_vline(xintercept = 140, linetype = "dashed", size = 1, colour = "red") + 
  geom_vline(xintercept = 130, linetype = "dashed", size = 1, colour = "blue") + 
  annotate("text", x = 125, y = 0.06, label = "Normal", hjust = 0) + 
  annotate("text", x = 150, y = 0.078, label = "Hypertention", hjust = 0, color = "red") + 
  theme_base() + xlab("Systolic BP (mmHg)")
  theme(axis.title.y = element_blank())

```

## Hypothesis testing

1. 정상인 중 과거 수축기 혈압 기준으로 고혈압군을 나눌 때 정상임에도 불구하고 고혈압 환자로 판정할 확률

$P(X \geq 140 | \mu = 123) = P((X - \mu)/(\sigma/\sqrt{n}) \geq (140-123)/(7/\sqrt{50})) = P(Z \geq 17.18) \approx 0$

2. 정상인 중 최근 변경 수축기 혈압 기준으로 고혈압군을 나눌 때 정상임에도 불구하고 고혈압 환자로 판정할 확률

$P(X \geq 130) | \mu = 123) = P(Z \geq $


# Chapter II: Clinical Research

## Overview 

\LARGE{\textbf{Research or trial?}}

### Research

\normalsize{자료의 수집과 분석 목적이 학술적 목적에 국한된 모든 종류의 연구 및 실험}

### Trial

\normalsize{자료의 수집과 분석 목적이 이윤추구 또는 허가에 목적이 있는 임상시험}

## Observational Study

### Cross-sectional study (단면적 관찰연구)

1. prevalence study
2. Diagostic test
3. Ecological study 
4. Validity, Reliability, and agreement study

### Longitudinal study (종단적 관찰연구)

1. Prospective study
2. Retrospective study

## Experimental Study

### Randomized controlled trial 

### Pilot study

### Exploratory study

### Confirmative study


# Type of outcome variables

## Primary outcomes

## Secondary outcomes

## Surrogate variables

## Global assessment variable

# Sample size calculation

## Overview

### Two approaches

1. Based on the marginal error rate $\rightarrow$ population based observational study
2. Based on the effectiveness between concerning groups $\rightarrow$ experimental study
  
\textbf{Both approaches are based on previous studies}

\textbf{Is your study entirely new?}

## Observational study

## Observational study: prevalence study

## Observational study: prevalence study

## Parallel design

## $2\times 2$ cross-over design 

## Factorial design

# Multiple comparison

## What makes data significant?

1. Data themselves contain unexpected errors
2. Bias
3. Just conincidence
4. Our hypothesis is working

## Torturing data

# Statistical Analysis 

## Overview

## Independent two sample t-test

1. Too easy, but very useful methodology for the comparison of sample means between two groups

## Analysis of Variance (ANOVA)

## Analysis of Covariance (ANCOVA)

## Simple or multiple regression

## Repeated Measures ANOVA

## Linear mixed effects model 

## Reliability analysis 

### Cohen's $\kappa$

### Cronbach's $\alpha$

### Intra Class Correlation (ICC)










